list_quartile1 = get_quartile1(x, na.rm = TRUE)
list_median    = get_median(x, na.rm = TRUE)
list_mean      = get_average(x, na.rm = TRUE)
list_quartile3 = get_quartile3(x, na.rm = TRUE)
list_percent90 = get_percentile90(x, na.rm = TRUE)
list_maximum   = get_maximum(x, na.rm = TRUE)
list_range     = get_range(x, na.rm = TRUE)
list_stdev     = get_stdev(x, na.rm = TRUE)
list_missing   = count_missing(x)
return(list(minimum = list_minimum,
percent10 = list_percent10,
quartile1 = list_quartile1,
median = list_median,
mean = list_mean,
quartile3 = list_quartile3,
percent90 = list_percent90,
maximum = list_maximum,
range = list_range,
stdev = list_stdev,
missing = list_missing
)
)
}
# print statistics function
print_stats <- function(x) {
n <- length(x)
for (i in 1:n) {
element_name <- str_pad(names(x)[i], width = 9, side = 'right')
element <- format(x[[i]], digits = 4, nsmall = 4)
cat(paste0(element_name, ': ', element, '\n'))
}
}
# rescale function
rescale100 <- function(x, xmin, xmax) {
z = 100 * ((x - xmin) / (xmax - xmin))
return(z)
}
# drop lowest function
drop_lowest <- function(x) {
x_min = get_minimum(x, na.rm = TRUE)
pos = match(x_min, x)
return(x[-pos])
}
# score homework function
score_homework <- function(x, drop=FALSE) {
if (drop) {
x <- drop_lowest(x)
}
return(get_average(x))
}
# score quiz function
score_quiz <- function(x, drop=FALSE) {
if (drop) {
x <- drop_lowest(x)
}
return(get_average(x))
}
# score lab function
score_lab <- function(x) {
if (x >= 11) {
return(100)
} else if (x >= 10) {
return(80)
} else if (x >= 9) {
return(60)
} else if (x >= 8) {
return(40)
} else if (x >= 7) {
return(20)
} else {
return(0)
}
}
stats <- summary_stats(c(1, 4, 7, NA, 10))
print_stats(stats)
test_that("NA is removed correctly", {
expect_equal(remove_missing(x), c(25, 51, 88, 19, 7, 74))
})
library(testthat)
context("Testing for remove_missing")
x <- c(25, 51, NA, 88, 19, NA, 7, 74)
test_that("NA is removed correctly", {
expect_equal(remove_missing(x), c(25, 51, 88, 19, 7, 74))
})
context("Testing for get_minimum")
test_that("Minimum value is identified", {
expect_equal(get_minimum(x, na.rm = TRUE), min(x, na.rm = TRUE))
expect_equal(get_minimum(x[-7], na.rm = TRUE), 19)
expect_equal(2 * (get_minimum(x, na.rm = TRUE)), 2 * min(x, na.rm = TRUE))
expect_error(2 * (get_minimum(x, na.rm = FALSE)), NA)
})
context("Testing for get_minimum")
test_that("Minimum value is identified", {
expect_equal(get_minimum(x, na.rm = TRUE), min(x, na.rm = TRUE))
expect_equal(get_minimum(x[-7], na.rm = TRUE), 19)
expect_equal(2 * (get_minimum(x, na.rm = TRUE)), 2 * min(x, na.rm = TRUE))
expect_error(2 * (get_minimum(x, na.rm = FALSE)), NA)
})
library(testthat)
context("Testing for remove_missing")
x <- c(25, 51, NA, 88, 19, NA, 7, 74)
test_that("NA is removed correctly", {
expect_equivalent(remove_missing(x), c(25, 51, 88, 19, 7, 74))
})
context("Testing for get_minimum")
test_that("Minimum value is identified", {
expect_equal(get_minimum(x, na.rm = TRUE), min(x, na.rm = TRUE))
expect_equal(get_minimum(x[-7], na.rm = TRUE), 19)
expect_equal(2 * (get_minimum(x, na.rm = TRUE)), 2 * min(x, na.rm = TRUE))
expect_error(2 * (get_minimum(x, na.rm = FALSE)), NA)
})
context("Testing for get_minimum")
test_that("Minimum value is identified", {
expect_equal(get_minimum(x, na.rm = TRUE), min(x, na.rm = TRUE))
expect_equal(get_minimum(x[-7], na.rm = TRUE), 19)
expect_equal(2 * (get_minimum(x, na.rm = TRUE)), 2 * min(x, na.rm = TRUE))
expect_error(2 * (get_minimum(x, na.rm = FALSE)), NA)
})
test_that("NA is removed correctly", {
expect_equivalent(remove_missing(x), c(25, 51, 88, 19, 7, 74))
})
test_that("NA is removed correctly", {
expect_equivalent(remove_missing(x), c(25, 51, 88, 19, 7, 74))
expect_type(remove_missing(x), vector)
})
test_that("NA is removed correctly", {
expect_equivalent(remove_missing(x), c(25, 51, 88, 19, 7, 74))
expect_type(remove_missing(x), "vector")
})
test_that("NA is removed correctly", {
expect_equivalent(remove_missing(x), c(25, 51, 88, 19, 7, 74))
expect_type(remove_missing(x), as.vector())
})
test_that("NA is removed correctly", {
expect_equivalent(remove_missing(x), c(25, 51, 88, 19, 7, 74))
expect_type(remove_missing(x), as.vector(x))
})
test_that("Maximum value is identified", {
expect_equal(get_minimum(x, na.rm = TRUE), max(x, na.rm = TRUE))
expect_equal(get_minimum(x[-4], na.rm = TRUE), 74)
expect_equal(2 * (get_maximum(x, na.rm = TRUE)), 2 * max(x, na.rm = TRUE))
expect_error(2 * (get_maximum(x, na.rm = FALSE)), NA)
})
test_that("Maximum value is identified", {
expect_equal(get_maximum(x, na.rm = TRUE), max(x, na.rm = TRUE))
expect_equal(get_maximum(x[-4], na.rm = TRUE), 74)
expect_equal(2 * (get_maximum(x, na.rm = TRUE)), 2 * max(x, na.rm = TRUE))
expect_error(2 * (get_maximum(x, na.rm = FALSE)), NA)
})
?range
test_that("Range is properly identified", {
expect_equal(get_range(x, na.rm = TRUE), 81)
expect_equal(get_range(x[-4], na.rm = TRUE), 67)
expect_equal(2 * (get_range(x, na.rm = TRUE)), 162)
expect_error(2 * (get_range(x, na.rm = FALSE)), NA)
})
quantile(x, 0.1)
quantile(x, 0.1, na.rm = TRUE)
quantile(x[-4], 0.1, na.rm = TRUE)
context("Testing for get_percentile10")
test_that("10th percentile is properly identified", {
expect_equal(get_percentile10(x, na.rm = TRUE), 13)
expect_equal(get_percentile10(x[-4], na.rm = TRUE), 11.8)
expect_equal(2 * (get_percentile10(x, na.rm = TRUE)), 26)
expect_error((get_percentile10(x, na.rm = FALSE)))
})
test_that("10th percentile is properly identified", {
expect_equal(get_percentile10(x, na.rm = TRUE), 13)
expect_equal(get_percentile10(x[-4], na.rm = TRUE), 11.8)
expect_equal(2 * (get_percentile10(x, na.rm = TRUE)), 26)
expect_error((get_percentile10(x, na.rm = FALSE)), NA)
})
quantile(x, na.rm = TRUE, 0.9)
quantile(x[-4], na.rm = TRUE, 0.9)
test_that("90th percentile is properly identified", {
expect_equal(get_percentile90(x, na.rm = TRUE), 81)
expect_equal(get_percentile90(x[-4], na.rm = TRUE), 64.8)
expect_equal(2 * (get_percentile90(x, na.rm = TRUE)), 162)
expect_error((get_percentile90(x, na.rm = FALSE)), NA)
})
quantile(x, na.rm = TRUE, 0.25)
quantile(x[-4], na.rm = TRUE, 0.25)
context("Testing for get_quartile1")
test_that("90th percentile is properly identified", {
expect_equal(get_quartile1(x, na.rm = TRUE), 20.5)
expect_equal(get_quartile1(x[-4], na.rm = TRUE), 19)
expect_equal(2 * (get_quartile1(x, na.rm = TRUE)), 41)
expect_error((get_quartile1(x, na.rm = FALSE)), NA)
})
quantile(x, na.rm = TRUE, 0.75)
quantile(x[-4], na.rm = TRUE, 0.75)
68.25 * 2
context("Testing for get_quartile3")
test_that("3rd quartile is properly identified", {
expect_equal(get_quartile3(x, na.rm = TRUE), 68.25)
expect_equal(get_quartile3(x[-4], na.rm = TRUE), 51)
expect_equal(2 * (get_quartile3(x, na.rm = TRUE)), 136.5)
expect_error((get_quartile3(x, na.rm = FALSE)), NA)
})
median(x, na.rm = TRUE)
median(x[=4], na.rm = TRUE)
median(x[-4], na.rm = TRUE)
context("Testing for get_median")
test_that("Median is properly identified", {
expect_equal(get_median(x, na.rm = TRUE), 38)
expect_equal(get_median(x[-4], na.rm = TRUE), 25)
expect_equal(2 * (get_median(x, na.rm = TRUE)), 76)
expect_error((get_median(x, na.rm = FALSE)), NA)
})
context("Testing for get_median")
test_that("Median is properly identified", {
expect_equal(get_median(x, na.rm = TRUE), 38)
expect_equal(get_median(x[-4], na.rm = TRUE), 25)
expect_equal(2 * (get_median(x, na.rm = TRUE)), 76)
expect_error((get_median(x, na.rm = FALSE)), NA)
})
mean(x, na.rm = TRUE)
mean(x[-4], na.rm = TRUE)
context("Testing for get_average")
test_that("Average is properly identified", {
expect_equal(get_average(x, na.rm = TRUE), 44)
expect_equal(get_average(x[-4], na.rm = TRUE), 35.2)
expect_equal(2 * (get_average(x, na.rm = TRUE)), 88)
expect_error((get_average(x, na.rm = FALSE)), NA)
})
sd(x, na.rm = TRUE)
context("Testing for get_stdev")
test_that("Standard deviation is properly identified", {
expect_equal(get_stdev(x, na.rm = TRUE), sd(x, na.rm = TRUE))
expect_equal(get_stdev(x[-4], na.rm = TRUE), sd(x[-4], na.rm = TRUE))
expect_equal(2 * (get_stdev(x, na.rm = TRUE)), 2 * sd(x, na.rm = TRUE))
expect_error((get_stdev(x, na.rm = FALSE)), NA)
})
x[-3]
x[-3][-5]
context("Testing for count_missing")
test_that("Standard deviation is properly identified", {
expect_equal(count_missing(x), 2)
expect_equal(count_missing(x[-3]), 1)
expect_equal(2 * (count_missing(x)), 4)
expect_error((count_missing(x[-3][-5])), 0)
})
context("Testing for count_missing")
test_that("Standard deviation is properly identified", {
expect_equal(count_missing(x), 2)
expect_equal(count_missing(x[-3]), 1)
expect_equal(2 * (count_missing(x)), 4)
expect_equal((count_missing(x[-3][-5])), 0)
})
summary_stats(x)
summary_stats(x)[[1]]
summary_stats(x)[[2]]
summary_stats(x)[[3]]
summary_stats(x)[[4]]
context("Testing for summary_stats")
test_that("Summary stats are properly identified", {
expect_equal(summary_stats(x)[[1]], 7)
expect_equal(summary_stats(x)[[2]], 13)
expect_equal(summary_stats(x)[[3]], 20.5)
expect_equal(summary_stats(x)[[4]], 38)
})
drop_lowest(x)
context("Testing for drop_lowest")
test_that("Lowest score is properly identified", {
expect_equal(drop_lowest(x), c(25, 51, NA, 88, 19, NA, 74))
})
2 * x
test_that("Lowest score is properly identified", {
expect_equal(drop_lowest(x), c(25, 51, NA, 88, 19, NA, 74))
expect_equal(2 * drop_lowest(x), c(50, 102, NA, 176, 38, NA, 148))
})
test_that("Lowest score is properly identified", {
expect_equal(drop_lowest(x), c(25, 51, NA, 88, 19, NA, 74))
expect_equal(2 * drop_lowest(x), c(50, 102, NA, 176, 38, NA, 148))
expect_equal(drop_lowest(x), c(25, 51, 88, 19, 74))
expect_equal(2 * drop_lowest(x), c(50, 102, 176, 38, 148))
})
context("Testing for drop_lowest")
test_that("Lowest score is properly identified", {
expect_equal(drop_lowest(x), c(25, 51, NA, 88, 19, NA, 74))
expect_equal(2 * drop_lowest(x), c(50, 102, NA, 176, 38, NA, 148))
expect_equal(drop_lowest(x[-3][-5]), c(25, 51, 88, 19, 74))
expect_equal(2 * drop_lowest(x[-3][-5]), c(50, 102, 176, 38, 148))
})
context("Testing for summary_stats")
test_that("Summary stats are properly calculated", {
expect_equal(summary_stats(x)[[1]], min(x, na.rm = TRUE))
expect_equal(summary_stats(x)[[2]], quantile(x, 0.1, na.rm = TRUE))
expect_equal(summary_stats(x)[[3]], quantile(x, 0.25, na.rm = TRUE))
expect_equal(summary_stats(x)[[4]], median(x, na.rm = TRUE))
})
test_that("Summary stats are properly calculated", {
expect_equal(summary_stats(x)[[1]], min(x, na.rm = TRUE))
expect_equal(summary_stats(x)[[2]], quantile(x, 0.1, na.rm = TRUE)[1])
expect_equal(summary_stats(x)[[3]], quantile(x, 0.25, na.rm = TRUE))
expect_equal(summary_stats(x)[[4]], median(x, na.rm = TRUE))
})
context("Testing for summary_stats")
test_that("Summary stats are properly calculated", {
expect_equal(summary_stats(x)[[1]], min(x, na.rm = TRUE))
expect_equal(summary_stats(x)[[2]], quantile(x, 0.1, na.rm = TRUE)[[1]])
expect_equal(summary_stats(x)[[3]], quantile(x, 0.25, na.rm = TRUE)[[1]])
expect_equal(summary_stats(x)[[4]], median(x, na.rm = TRUE))
})
rescale100(x)
rescale100(x, xmin = 0, xmax = 90)
rescale100(x, xmin = 0, xmax = 100)
rescale100(x, xmin = 10, xmax = 90)
rescale100(x, xmin = 0, xmax = 80)
context("Testing for rescale100")
test_that("Data is properly rescaled to 100", {
expect_equal(rescale100(x, xmin = 0, xmax = 90)[1], 27.777778)
expect_equal(rescale100(x, xmin = 0, xmax = 100)[1], 25)
expect_equal(rescale100(x, xmin = 10, xmax = 90)[1], 18.75)
expect_equal(rescale100(x, xmin = 0, xmax = 80)[4], 110)
})
score_homework(x)
x <- x[-3][-5]
score_homework(x)
score_homework(x, drop = TRUE)
test_that("Homework is properly scored", {
expect_equal(score_homework(x), 44)
expect_equal(score_homework(x, drop = TRUE), 51.4)
})
score_homework(x[-5], drop = TRUE)
score_homework(x[-5])
score_homework(x[-6])
score_homework(x[-6], drop = TRUE)
context("Testing for score_homework")
test_that("Homework is properly scored", {
expect_equal(score_homework(x), 44)
expect_equal(score_homework(x, drop = TRUE), 51.4)
expect_equal(score_homework(x[-6]), 38)
expect_equal(score_homework(x[-6], drop = TRUE), 45.75)
})
context("Testing for score_quiz")
test_that("Quizzes are properly scored", {
expect_equal(score_quiz(x), 44)
expect_equal(score_quiz(x, drop = TRUE), 51.4)
expect_equal(score_quiz(x[-6]), 38)
expect_equal(score_quiz(x[-6], drop = TRUE), 45.75)
})
context("Testing for score_lab")
test_that("Lab attendance is properly scored", {
expect_equal(score_lab(12), 100)
expect_equal(score_lab(11), 100)
expect_equal(score_lab(2), 0)
expect_equal(score_lab(7), 20)
})
context("Testing for score_lab")
test_that("Lab attendance is properly scored", {
expect_equal(score_lab(12), 100)
expect_equal(score_lab(11), 100)
expect_equal(score_lab(2), 0)
expect_equal(score_lab(7.4), 20)
})
rm(list = ls())
# test script
library(testthat)
# source functions to be tested
source('functions.R')
sink('../output/test-reporter.txt')
test_file('tests.R')
sink()
remove_missing(c(NA, NA, NA))
test_that("NA is removed correctly", {
expect_equivalent(remove_missing(x), c(25, 51, 88, 19, 7, 74))
expect_equivalent(remove_missing(c(NA, NA)), logical(0))
})
x <- c(25, 51, NA, 88, 19, NA, 7, 74)
test_that("NA is removed correctly", {
expect_equivalent(remove_missing(x), c(25, 51, 88, 19, 7, 74))
expect_equivalent(remove_missing(c(NA, NA)), logical(0))
})
remove_missing(c(NA, NA))[-1]
rm(list = ls())
# test script
library(testthat)
# source functions to be tested
source('functions.R')
sink('../output/test-reporter.txt')
test_file('tests.R')
sink()
runApp('~/Desktop/stat133/stat133-hws-fall17/hw04/app/gradevis.R')
runApp('~/Desktop/stat133/stat133-hws-fall17/hw04/app/gradevis.R')
# test script
library(testthat)
# source functions to be tested
source('functions.R')
sink('../output/test-reporter.txt')
test_file('tests.R')
sink()
# -------------------------------------------------------
# Title: clean-data-script
# Description: script to produce clean data for hw04
# Input: rawscores.csv
# Output: multiple summaries and cleanscores.csv
# Author: Doug Koerber
# -------------------------------------------------------
# load packages and source functions
library(readr)
library(dplyr)
source('functions.R')
# load data, define a border to be used in text output, set size of data
scores <- as.data.frame(read.csv('../data/rawdata/rawscores.csv'))
border <- "-------------------------------------------------------------------"
n_rows <- nrow(scores)
n_cols <- ncol(scores)
# sink structure of the data and summary stats for all variables
sink('../output/summary-rawscores.txt')
cat(paste0("structure of the scores data.frame\n", border, "\n"))
str(scores)
for (i in 1:n_cols) {
col <- names(scores)[i]
cat(paste0("\n", col, "\n", border, "\n"))
stats <- summary_stats(scores[ , i])
print_stats(stats)
}
sink()
# for loop to replace NA values with 0
for (i in 1:n_rows) {
for (j in 1:n_cols) {
if (is.na(scores[i, j])) {
scores[i, j] = 0
}
}
}
# rescaling all quiz scores to be in percent
scores[ , 'QZ1'] <- rescale100(scores[ , 'QZ1'], xmin = 0, xmax = 12)
scores[ , 'QZ2'] <- rescale100(scores[ , 'QZ2'], xmin = 0, xmax = 18)
scores[ , 'QZ3'] <- rescale100(scores[ , 'QZ3'], xmin = 0, xmax = 20)
scores[ , 'QZ4'] <- rescale100(scores[ , 'QZ4'], xmin = 0, xmax = 20)
# rescaling all test scores to be in percent
scores <- scores %>%
mutate(Test1 = rescale100(scores[ , 'EX1'], xmin = 0, xmax = 80))
scores <- scores %>%
mutate(Test2 = rescale100(scores[ , 'EX2'], xmin = 0, xmax = 90))
# calculating the total homework score while dropping the lowest grade
hws <- c('HW1', 'HW2', 'HW3', 'HW4', 'HW5', 'HW6', 'HW7', 'HW8', 'HW9')
scores <- mutate(scores, Homework = 0)
for (i in 1:n_rows) {
grades = as.numeric(scores[i, hws])
scores[i, 'Homework'] = score_homework(grades, drop = TRUE)
}
# calculating the total quiz score while dropping the lowest grade
qzs <- c('QZ1', 'QZ2', 'QZ3', 'QZ4')
scores <- mutate(scores, Quiz = 0)
for (i in 1:n_rows) {
grades = as.numeric(scores[i, qzs])
scores[i, 'Quiz'] = score_quiz(grades, drop = TRUE)
}
# calculating the total lab attendance score
lab <- c('ATT')
scores <- mutate(scores, Lab = 0)
for (i in 1:n_rows) {
grades = as.numeric(scores[i, lab])
scores[i, 'Lab'] = score_lab(grades)
}
# add overall grade to the data
scores <- scores %>%
mutate(Overall = (0.1 * Lab) +
(0.3 * Homework) +
(0.15 * Quiz) +
(0.2 * Test1) +
(0.25 * Test2)
)
# convert overall grade from numeric to character
scores <- mutate(scores, Grade = 'n')
for (i in 1:n_rows) {
grade = scores[i, 'Overall']
if (grade >= 95) {
scores[i, 'Grade'] = 'A+'
} else if (grade >= 90) {
scores[i, 'Grade'] = 'A'
} else if (grade >= 88) {
scores[i, 'Grade'] = 'A-'
} else if (grade >= 86) {
scores[i, 'Grade'] = 'B+'
} else if (grade >= 82) {
scores[i, 'Grade'] = 'B'
} else if (grade >= 79.5) {
scores[i, 'Grade'] = 'B-'
} else if (grade >= 77.5) {
scores[i, 'Grade'] = 'C+'
} else if (grade >= 70) {
scores[i, 'Grade'] = 'C'
} else if (grade >= 60) {
scores[i, 'Grade'] = 'C-'
} else if (grade >= 50) {
scores[i, 'Grade'] = 'D'
} else {
scores[i, 'Grade'] = 'F'
}
}
# for loop to sink summary stats for each of the listed assignments
summaries <- c('Lab', 'Homework', 'Quiz', 'Test1', 'Test2', 'Overall')
for (i in 1:length(summaries)) {
sink(paste0('../output/', summaries[i], '-stats.txt'))
cat(paste0(summaries[i], "\n", border, "\n"))
stats <- summary_stats(scores[ , i])
print_stats(stats)
sink()
}
# sink the structure of the cleaned data
sink('../output/summary-cleanscores.txt')
cat(paste0("clean scores\n", border, "\n"))
str(scores)
sink()
# export the cleaned data
write.csv(scores, '../data/cleandata/cleanscores.csv')
dat <- read.csv("../data/cleandata/cleanscores.csv")
View(dat)
